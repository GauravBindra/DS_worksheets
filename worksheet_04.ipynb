{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 04\n",
    "\n",
    "Name:  Gauravdeep Singh Bindra\n",
    "UID: U23346660\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Distance & Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance & Similarity\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "a) In the minkowski distance, describe what the parameters p and d are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p - determines the type of Minkowski distance that is being calculated. Eg. p = 1 for Manhattan Distance and p = 2 for Euclidean distance. We raise the error to the power p and the whole summation to the power 1/p \n",
    "d - The number of dimensions of the points between which we are calculating the distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In your own words describe the difference between the Euclidean distance and the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distance represents the shortest distance between the two points in the d-dimensioanl space. Whereas Manhattan distance represents the absolute distance between co-ordinates summed across all dimensions. \n",
    "Euclidean is preferable to use in most situations as it is easier to optimise. But if that dataset has binary attributes or in a game/catalogue situation where differences in individual attributes matter, there manhattan distance is preferred. Manhattan is also preferred in very high dimensional space to overcome the \"curse of dimensionality\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"/Users/gauravbindra/desktop/DS_worksheet/manhattan_euclidean.png\" alt = \"Manhattan vs Euclidean Distance\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Manhattan vs Euclidean Distance](/Users/gauravbindra/desktop/DS_worksheet/manhattan_euclidean.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A = (0, 0) and B = (1, 1). When:\n",
    "\n",
    "- p = 1, d(A, B) = 2\n",
    "- p = 2, d(A, B) = $\\sqrt{2} = 1.41$\n",
    "- p = 3, d(A, B) = $2^{1/3} = 1.26$\n",
    "- p = 4, d(A, B) = $2^{1/4} = 1.19$\n",
    "\n",
    "c) Describe what you think distance would look like when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When p is very large then distance would tend/approximate to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Is the minkowski distance still a distance function when p < 1? Expain why / why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Np, since it doesnt follow the triangle inequality when p<1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) when would you use cosine similarity over the euclidan distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the angle/similarity between two objects matters more than the distance between them. Eg. In case of documents similarity. The proportion of words matters much more than the difference across all words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) what does the jaccard distance account for that the manhattan distance doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard distance is the size of the set distance. Since its a set, so it only matters if an attribute is present or not. The frequency of that doesnt matter. Useful in case of calculating documents simiarity/binary data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"hello my name is Alice\"  \n",
    "s2 = \"hello my name is Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the union of words from both sentences, we can represent each sentence as a vector. Each element of the vector represents the presence or absence of the word at that index.\n",
    "\n",
    "In this example, the union of words is (\"hello\", \"my\", \"name\", \"is\", \"Alice\", \"Bob\") so we can represent the above sentences as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1]\n",
    "#     hello my name is    Bob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'hello', 'Alice', 'name', 'Bob', 'my']\n",
      "[1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus = [s1, s2]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)\n",
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new sentence to our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"hi my name is Claude\"\n",
    "corpus.append(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the new union of words used to represent s1, s2, and s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'hello', 'Alice', 'name', 'hi', 'Claude', 'Bob', 'my']\n"
     ]
    }
   ],
   "source": [
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Represent s1, s2, and s3 as vectors as above, using this new set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 0, 0, 0, 1], [1, 1, 0, 1, 0, 0, 1, 1], [1, 0, 0, 1, 1, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for i in range(len(corpus)):\n",
    "    delta = [1 if x in corpus[i] else 0 for x in all_words]\n",
    "    vectors.append(delta)\n",
    "    # print(delta)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that computes the manhattan distance between two vectors. Which pair of vectors are the most similar under that distance function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar vectors are  [[1, 1, 1, 1, 0, 0, 0, 1], [1, 1, 0, 1, 0, 0, 1, 1]] with difference  2\n"
     ]
    }
   ],
   "source": [
    "def Manhattan(v1,v2):\n",
    "    n = len(v1)\n",
    "    res = 0 \n",
    "    for i in range(n):\n",
    "        diff = abs(int(v1[i])-int(v2[i]))\n",
    "        res+=diff \n",
    "    return res \n",
    "min_diff = float('inf')\n",
    "similar_vectors=[]\n",
    "for v1 in vectors:\n",
    "    for v2 in vectors: \n",
    "        if v1==v2:\n",
    "            continue \n",
    "        # print(v1,v2)\n",
    "        diff = Manhattan(v1,v2)\n",
    "        # print(diff,min_diff)\n",
    "        if diff < min_diff:\n",
    "            similar_vectors = [v1,v2]\n",
    "            min_diff=diff\n",
    "print(\"The most similar vectors are \", similar_vectors, \"with difference \", min_diff)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a matrix of all these vectors (row major) and add the following sentences in vector form:\n",
    "\n",
    "- \"hi Alice\"\n",
    "- \"hello Claude\"\n",
    "- \"Bob my name is Claude\"\n",
    "- \"hi Claude my name is Alice\"\n",
    "- \"hello Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How many rows and columns does this matrix have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) When using the Manhattan distance, which two sentences are the most similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
